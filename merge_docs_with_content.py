#!/usr/bin/env python3
"""
åˆå¹¶ Word æ–‡æ¡£ï¼ˆå¤„ç† MHT/altChunk æ ¼å¼å’Œæ™®é€š Word æ ¼å¼ï¼‰
ä¿®å¤ç‰ˆ v3: ä½¿ç”¨æ›´å¥å£®çš„ HTML æå–
"""
import sys
import os
import glob
import zipfile
import html
import quopri
import re
from xml.etree import ElementTree as ET
from docx import Document
from docx.shared import Pt, RGBColor
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT

# Word å‘½åç©ºé—´
NAMESPACES = {
    'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main',
}

def clean_html_text(text):
    """æ¸…ç† HTML æ–‡æœ¬"""
    # ç§»é™¤æ ‡ç­¾
    text = re.sub(r'\u003c[^\u003e]+\u003e', ' ', text)
    # è§£ç å®ä½“
    text = html.unescape(text)
    # åˆå¹¶å¤šä¸ªç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)
    # ç§»é™¤é¦–å°¾ç©ºæ ¼
    text = text.strip()
    return text

def extract_text_from_mht(mht_content):
    """ä» MHT å†…å®¹ä¸­æå–æ–‡æœ¬"""
    try:
        decoded = quopri.decodestring(mht_content.encode()).decode('utf-8', errors='ignore')
        decoded = decoded.replace('=\n', '')
    except:
        decoded = mht_content
    
    texts = []
    
    # æå–æ ‡é¢˜ï¼ˆå¤šç§æ¨¡å¼ï¼‰
    title = ""
    title_match = re.search(r'activity-name[^\u003e]*\u003e([^\u003c]+)', decoded)
    if title_match:
        title = clean_html_text(title_match.group(1))
    if not title:
        title_match = re.search(r'rich_media_title[^\u003e]*\u003e([^\u003c]+)', decoded)
        if title_match:
            title = clean_html_text(title_match.group(1))
    if title:
        texts.append(title)
    
    # æå–æ­£æ–‡ - æ–¹æ³•1: ä» js_content æˆ– rich_media_content æå–
    content = ""
    
    # å°è¯•æ‰¾åˆ° js_content å¹¶æå–å…¶æ‰€æœ‰æ–‡æœ¬
    js_content_match = re.search(r'id=[\"\']js_content[\"\'][^\u003e]*\u003e(.*?)\u003cdiv[^\u003e]*id=', decoded, re.DOTALL)
    if js_content_match:
        content = js_content_match.group(1)
    
    # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä» js_article_content æå–
    if not content:
        js_article_match = re.search(r'id=[\"\']js_article_content[\"\'][^\u003e]*\u003e(.*)', decoded, re.DOTALL)
        if js_article_match:
            content = js_article_match.group(1)
    
    # æå–æ‰€æœ‰æ–‡æœ¬æ®µè½
    if content:
        # æå–æ‰€æœ‰ <p> æ ‡ç­¾å†…å®¹
        paragraphs = re.findall(r'\u003cp[^\u003e]*\u003e(.*?)\u003c/p\u003e', content, re.DOTALL)
        for para in paragraphs:
            text = clean_html_text(para)
            if text and len(text) > 5:
                texts.append(text)
    
    # å¤‡ç”¨æ–¹æ¡ˆï¼šå¦‚æœæ²¡æœ‰æå–åˆ°å†…å®¹ï¼Œç›´æ¥æå–æ‰€æœ‰æ–‡æœ¬èŠ‚ç‚¹
    if len(texts) <= 1:
        all_texts = re.findall(r'\u003e([^<\u003e]{20,})\u003c', decoded)
        for text in all_texts:
            text = clean_html_text(text)
            if text and len(text) > 10 and text not in texts:
                texts.append(text)
    
    return '\n\n'.join(texts)

def extract_text_from_xml(xml_content):
    """ä» Word document.xml ä¸­æå–æ–‡æœ¬"""
    texts = []
    try:
        root = ET.fromstring(xml_content)
        for para in root.findall('.//w:p', NAMESPACES):
            para_texts = []
            for t in para.findall('.//w:t', NAMESPACES):
                if t.text:
                    para_texts.append(t.text)
            if para_texts:
                texts.append(''.join(para_texts))
    except Exception as e:
        print(f"XMLè§£æé”™è¯¯: {e}")
    
    return '\n\n'.join(texts)

def extract_text_fallback(file_path):
    """ä½¿ç”¨ zipfile ç›´æ¥è¯»å–ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    try:
        with zipfile.ZipFile(file_path, 'r') as z:
            if 'word/afchunk.mht' in z.namelist():
                mht_content = z.read('word/afchunk.mht').decode('utf-8', errors='ignore')
                return extract_text_from_mht(mht_content)
            
            if 'word/document.xml' in z.namelist():
                xml_content = z.read('word/document.xml')
                return extract_text_from_xml(xml_content)
    except Exception as e:
        print(f"å¤‡ç”¨è¯»å–å¤±è´¥: {e}")
    
    return ""

def extract_text_from_docx(file_path):
    """ä» docx ä¸­æå–æ–‡æœ¬ï¼ˆæ”¯æŒæ‰€æœ‰æ ¼å¼ï¼‰"""
    try:
        doc = Document(file_path)
        texts = []
        for para in doc.paragraphs:
            if para.text.strip():
                texts.append(para.text.strip())
        
        if texts and len(texts) > 0:
            return '\n\n'.join(texts)
    except Exception as e:
        pass
    
    return extract_text_fallback(file_path)

def merge_docs_with_content(folder_path, output_path):
    """åˆå¹¶æ–‡æ¡£ï¼ŒåŒ…å«å®Œæ•´å†…å®¹"""
    
    if not os.path.isdir(folder_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
        return False
    
    search_pattern = os.path.join(folder_path, "*.docx")
    files = sorted(glob.glob(search_pattern))
    
    if not files:
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ° docx æ–‡ä»¶: {search_pattern}")
        return False
    
    print(f"ğŸ“ æ–‡ä»¶å¤¹: {folder_path}")
    print(f"ğŸ“Š æ‰¾åˆ° {len(files)} ä¸ªæ–‡æ¡£")
    print("ğŸ“ å¼€å§‹åˆå¹¶...\n")
    
    merged_doc = Document()
    success_count = 0
    empty_count = 0
    
    for i, file_path in enumerate(files, 1):
        try:
            file_name = os.path.splitext(os.path.basename(file_path))[0]
            
            print(f"  [{i}/{len(files)}] å¤„ç†: {file_name[:50]}...", end=" ")
            
            if i > 1:
                merged_doc.add_page_break()
            
            title_para = merged_doc.add_paragraph()
            title_run = title_para.add_run(file_name)
            title_run.font.size = Pt(16)
            title_run.font.bold = True
            title_run.font.color.rgb = RGBColor(0x8B, 0x5A, 0x2B)
            title_para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
            
            merged_doc.add_paragraph()
            
            content = extract_text_from_docx(file_path)
            if content:
                paragraphs = content.split('\n\n')
                for para_text in paragraphs:
                    if para_text.strip():
                        para = merged_doc.add_paragraph()
                        para.add_run(para_text.strip())
                print(f"âœ… ({len(paragraphs)} æ®µ)")
                success_count += 1
            else:
                print("âš ï¸ æ— å†…å®¹")
                empty_count += 1
            
        except Exception as e:
            print(f"\n  âŒ é”™è¯¯: {e}")
            continue
    
    merged_doc.save(output_path)
    print(f"\n{'='*50}")
    print(f"âœ… åˆå¹¶å®Œæˆï¼")
    print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_path}")
    print(f"ğŸ“Š æ€»æ–‡æ¡£æ•°: {len(files)}")
    print(f"âœ… æˆåŠŸæå–: {success_count}")
    print(f"âš ï¸  æ— å†…å®¹: {empty_count}")
    return True

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("åˆå¹¶ Word æ–‡æ¡£å·¥å…·ï¼ˆä¿®å¤ç‰ˆ v3ï¼‰")
        print("")
        print("ç”¨æ³•:")
        print("  python3 merge_docs_with_content.py <è¾“å…¥æ–‡ä»¶å¤¹> <è¾“å‡ºæ–‡ä»¶>")
        print("")
        print("ç¤ºä¾‹:")
        print("  python3 merge_docs_with_content.py ./my_docs ./merged.docx")
        sys.exit(1)
    
    folder = sys.argv[1]
    output = sys.argv[2]
    merge_docs_with_content(folder, output)
